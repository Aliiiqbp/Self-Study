{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF and BM25 implemenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'hi there I wanted to say tha I am a good person who is very nice'\n",
    "doc2 = 'there is a big bear in the forest'\n",
    "doc3 = 'there is a big wolf in the jungle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.137\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "q = 'bear'\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "def tf_idf(query, doc):\n",
    "    words = doc.split()\n",
    "    tf = words.count(query) / len(words)\n",
    "    idf = math.log(len(docs) / sum([1 for doc in docs if query in doc]))\n",
    "    return round(tf * idf, 3)\n",
    "\n",
    "\n",
    "print(tf_idf(q, doc1)) \n",
    "print(tf_idf(q, doc2))\n",
    "print(tf_idf('is', doc2))\n",
    "print(tf_idf(q, doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 'person', 'jungle', 'good', 'big', 'wolf', 'wanted', 'who', 'bear', 'say', 'forest', 'in', 'is', 'tha', 'to', 'nice', 'very', 'there', 'hi', 'am', 'I', 'the'}\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "vocab = set(doc1.split() + doc2.split() + doc3.split())\n",
    "print(vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.069 0.    0.069 0.    0.    0.069 0.069 0.    0.069 0.    0.\n",
      " 0.    0.069 0.069 0.069 0.069 0.    0.069 0.069 0.137 0.   ] (22,)\n",
      "[0.    0.    0.    0.    0.051 0.    0.    0.    0.137 0.    0.137 0.051\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ] (22,)\n",
      "[0.    0.    0.137 0.    0.051 0.137 0.    0.    0.    0.    0.    0.051\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ] (22,)\n"
     ]
    }
   ],
   "source": [
    "vec_doc1 = np.array([tf_idf(word, doc1) for word in vocab])\n",
    "vec_doc2 = np.array([tf_idf(word, doc2) for word in vocab])\n",
    "vec_doc3 = np.array([tf_idf(word, doc3) for word in vocab])\n",
    "\n",
    "print(vec_doc1, vec_doc1.shape)\n",
    "print(vec_doc2, vec_doc2.shape)\n",
    "print(vec_doc3, vec_doc3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.        ]\n",
      " [0.         1.         0.12171268]\n",
      " [0.         0.12171268 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Stack the document vectors into a matrix\n",
    "tf_idf_matrix = np.vstack([vec_doc1, vec_doc2, vec_doc3])\n",
    "\n",
    "# Compute the cosine similarities\n",
    "cosine_similarities = cosine_similarity(tf_idf_matrix)\n",
    "\n",
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bear': [0.0, 0.228, 0.0], 'big forest': [0.0, 0.337, 0.109], 'nice person': [0.144, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# BM25 parameters\n",
    "k1 = 1.5\n",
    "b = 0.75\n",
    "\n",
    "# Compute average document length\n",
    "avg_doc_len = sum(len(doc.split()) for doc in docs) / len(docs)\n",
    "\n",
    "def bm25(query, doc, k1=k1, b=b):\n",
    "    words = doc.split()\n",
    "    doc_len = len(words)\n",
    "    score = 0\n",
    "    for term in query.split():\n",
    "        tf = words.count(term) / doc_len\n",
    "        idf = math.log((len(docs) - sum([1 for d in docs if term in d]) + 0.5) / (sum([1 for d in docs if term in d]) + 0.5) + 1)\n",
    "        score += idf * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avg_doc_len))))\n",
    "    return round(score, 3)\n",
    "\n",
    "# Example queries\n",
    "queries = ['bear', 'big forest', 'nice person']\n",
    "\n",
    "# Compute BM25 scores for each query against each document\n",
    "bm25_scores = {query: [bm25(query, doc) for doc in docs] for query in queries}\n",
    "\n",
    "print(bm25_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
